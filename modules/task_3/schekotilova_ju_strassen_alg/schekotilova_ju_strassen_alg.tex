\documentclass{report}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{luainputenc}
\usepackage[english, russian]{babel}
\usepackage[pdftex]{hyperref}
\usepackage[14pt]{extsizes}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{indentfirst}

\geometry{a4paper,top=2cm,bottom=3cm,left=2cm,right=1.5cm}
\setlength{\parskip}{0.5cm}
\setlist{nolistsep, itemsep=0.3cm,parsep=0pt}

\lstset{language=C++,
		basicstyle=\footnotesize,
		keywordstyle=\color{blue}\ttfamily,
		stringstyle=\color{red}\ttfamily,
		commentstyle=\color{green}\ttfamily,
		morecomment=[l][\color{magenta}]{\#}, 
		tabsize=4,
		breaklines=true,
  		breakatwhitespace=true,
  		title=\lstname,       
}

\makeatletter
\renewcommand\@biblabel[1]{#1.\hfil}
\makeatother

\begin{document}

\begin{titlepage}

\begin{center}
Министерство науки и высшего образования Российской Федерации
\end{center}

\begin{center}
Федеральное государственное автономное образовательное учреждение высшего образования \\
Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского
\end{center}

\begin{center}
Институт информационных технологий, математики и механики
\end{center}

\vspace{4em}

\begin{center}
\textbf{\LargeОтчет по лабораторной работе} \\
\end{center}
\begin{center}
\textbf{\LargeУмножение плотных матриц. Элементы типа double. Алгоритм Штрассена.} \\
\end{center}

\vspace{4em}

\newbox{\lbox}
\savebox{\lbox}{\hbox{text}}
\newlength{\maxl}
\setlength{\maxl}{\wd\lbox}
\hfill\parbox{7cm}{
\hspace*{5cm}\hspace*{-5cm}\textbf{Выполнил:} \\ студент группы 381806-3 \\ Щекотилова Ю. А.\\
\\
\hspace*{5cm}\hspace*{-5cm}\textbf{Проверил:}\\ доцент кафедры МОСТ, \\ кандидат технических наук \\ Сысоев А. В.\\
}
\vspace{\fill}

\begin{center} Нижний Новгород \\ 2020 \end{center}

\end{titlepage}

\setcounter{page}{2}

% Содержание
\tableofcontents
\newpage

% Введение
\section*{Введение}
\addcontentsline{toc}{section}{Введение}
Одной из самых распространенных задач в математике является перемножение матриц. Самый известный способ - это, конечно же, перемножение строчки на столбец, данный метод известен, наверное, каждому студенту. Но что, если размеры нашей матрицы больше, чем трехзначные числа. Справится с таким перемножением сложно не только человеку, но даже компьютеру. Поэтому математики придумывают различные методы, чтобы сократить время выполнения данного перемножения. Одним из таких математиков является Фолькер Штрассен, который придумал свой метод перемножения. В отличии от традиционного перемножения, которое работает за время O$(n^3)$, его алгоритм выполняет умножает за время O$(n^{2.81})$, что дает выигрыш на больших плотных матрицах, начиная с размера 64х64.
 
\par В данной лабораторной работе будет рассматрваться Алгоритм Штрассена, который работает с квадратными матрицами. Для умножения матриц алгоритм Штрассена использует семь формул. Замечательно, что как сами формулы, так и их использование не требуют, чтобы умножение элементов матриц было коммутативным. Это означает, в частности, что сами эти элементы могут быть матрицами, а значит, алгоритм Штрассена можно применять рекурсивно.
\newpage

% Постановка задачи
\section*{Постановка задачи}
\addcontentsline{toc}{section}{Постановка задачи}
В данной лабораторной работе необходимо реализовать программу, которая будет выполнять умножение плотных матриц с элементами типа double методом Штрассена. Требуется реализовать последовательную и параллельную (с использованием средств MPI) версии  и провести анализ по времени работы. А также подтвердить корректность (используя Google Testing Framework) и сделать выводы.
\newpage

% Метод решения
\section*{Метод решения}
\addcontentsline{toc}{section}{Метод решения}
Алгоритм Штрассена для вещественных чисел, применяемый для квадратных матриц, заключается в следующем:
\begin{itemize}
    \item Проверяем размер матрицы, если меньше критического значения, то используем обычный метод;
    \item Разделяем матрицы A и B на 4 квадратных подматрицы одинаковой размерности;
    \item Вычисляем формулы Штрассена, т.е. выполняем рекурсивное умножение, используя впомогательные функции сложения и вычитания матриц;
    \item Находим результирующие блоки для матрицы С;
    \item Формируем матрицу С из результирующиих блоков;
\end{itemize}
\newpage

% Схема распараллеливания
\section*{Схема распараллеливания}
\addcontentsline{toc}{section}{Схема распараллеливания}
Чтобы реализовать параллельную версию программы необходимо:
\begin{itemize}
    \item Проверить размер матрицы, если меньше 64, то используем последовательную версию;
    \item Создать матрицы A и B из блоков подматриц (A11, A12, A21, A22, B11, B12, B21, B22);
    \item Передать значение размера матриц из корневого процесса всем процессам группы, включая себя;
    \item Отправить элементы каждого блока из корневого процесса остальным;
    \item Вычислить вспомогательные значение из формул Штрассена, используя последовательный алгоритм;
    \item Получить подматрицы в корневом процессе;
    \item Сформировать результирующую матрицу.
\end{itemize}
\newpage

% Описание программной реализации
\section*{Описание программной реализации}
\addcontentsline{toc}{section}{Описание программной реализации}
Перед тем как реализовать параллельную версию алгоитма Штрассена необходимо создать следующие функции:
\begin {enumerate}
\item Арифметические операции, производимые с матрицами (сложение двух матриц, вычитаение двух матриц, сложение четырех матриц, а также сложение трех матриц, из результата которой вычитается одна матрица), которые выполняются с помощью функций:
\begin{lstlisting}
const std::vector<double> addition_of2m(const std::vector<double>& m1, const std::vector<double>& m2, int size)
const std::vector<double> subtraction_of2m(const std::vector<double>& m1, const std::vector<double>& m2, int size)
const std::vector<double> addition_of4m(const std::vector<double>& m1, const std::vector<double>& m2, const std::vector<double>& m3, const std::vector<double>& m4, int size)
const std::vector<double> add_of3_sub_of4(const std::vector<double>& m1, const std::vector<double>& m2, const std::vector<double>& m3, const std::vector<double>& m4, int size) 
\end{lstlisting}
В этих функциях в качестве входных параметров передаются константные ссылки на матрицы, а также размер этих матриц. А на выходе получаем результирующую матрицу.
\item Функция, которая разделяет матрицу на 4 равных по размеру блока
\begin{lstlisting}
void getFourMatrixBlocks(const std::vector<double>& A, std::vector<double>* A11,
  std::vector<double>* A12, std::vector<double>* A21, std::vector<double>* A22,
    int n_A)
\end{lstlisting}
На входе функция получает константные ссылки на подматрицы главной матрицы, матрицу,
\end{enumerate}
Последовательный алгоритм Штрассена вызывается с помощью функции
\begin{lstlisting}
const std::vector<double> getSequentialOperations(const std::vector<double>& m1, const std::vector<double>& m2, int n)
\end{lstlisting}
\par В качестве входных параметров передаются константные ссылки на матрицы А и В, а также размер этих матриц. А на выходе получается результирующая матрица С.
Аналогичная стуация с параллельной реализацией.
\newpage

% Подтверждение корректности
\section*{Подтверждение корректности}
\addcontentsline{toc}{section}{Подтверждение корректности}
Для подтверждения корректности в программе представлен набор тестов, разработанных с помощью использования Google C++ Testing Framework.
\par Набор представляет из себя тесты, которые проверяют корректность входных данных (матрицы, которые нужно перемножить), корректность вычислений (сравниваются матрицы, полученные благодаря параллельной и последовательной реализации алгоритма Штрассена), а также эффективность (вычисление времени, занимаемого последовательной и параллельной реализацией сравнение полученных данных).
\par Успешное прохождение всех тестов доказывает корректность работы программного комплекса.
\newpage

% Результаты экспериментов
\section*{Результаты экспериментов}
\addcontentsline{toc}{section}{Результаты экспериментов}
Вычислительные эксперименты для оценки эффективности параллельной реализации метода Штрассена проводились на оборудовании со следующей аппаратной конфигурацией:

\begin{itemize}
\item Процессор: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz, ядер: 4, логических процессоров: 8;
\item Оперативная память: 8,00 ГБ, 2400 MHz;
\item ОС: Microsoft Windows 10 Home, версия 2004 сборка 19041.685.
\end{itemize}

\par Для проведения экспериментов алгоритм Штрассена применяем на матрице размером 1024$\times$1024.
\par Результаты экспериментов представлены в Таблице 1.

\begin{table}[!h]
\caption{Результаты вычислительных экспериментов}
\centering
\begin{tabular}{lllll}
Процессы & Последовательно & Параллельно & Ускорение   \\
1        & 1.10990         & 0.98862     & 1.122       \\
2        & 1.27662         & 0.61063     & 2.09        \\
3        & 0.93471         & 0.57732     & 1.619       \\
4        & 0.94572         & 0.37291     & 2.536       \\
5        & 0.94420         & 0.38919     & 2.426       \\
6        & 0.93446         & 0.42166     & 2,216       \\
7        & 0.95805         & 0.33419     & 2.866       \\
8        & 1.02938         & 0.38942     & 2.643       \\
\end{tabular}
\end{table}
\par По данным, полученным в результате экспериментов, можно сделать вывод о том, что параллельный случай работает действительно быстрее, чем последовательный. 
\par Кроме того, можно сделать вывод, что при данной аппаратной конфигурации наиболее эффективным будет использование 4-8 процессов для параллельного алгоритма Штрассена.
\newpage

% Заключение
\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}
В результате лабораторной работы были разработаны последовательная и параллельная версии алгоритма Штрассена.
\par Основной задачей данной лабораторной работы была реализация параллельной версии с использованием средств MPI, которая должна была быть эффективнее последовательной. Эта задача была успешно достигнута. Об этом говорят результаты экспериментов, проведенных в ходе работы. Они показывают, что параллельный вариант работает действительно быстрее, чем последовательный. 
\par Кроме того, были разработаны и доведены до успешного выполнения тесты, созданные для данного программного проекта с использованием Google C++ Testing Framework и необходимые для подтверждения корректности работы программы.
\newpage

% Список литературы
\begin{thebibliography}{1}
\addcontentsline{toc}{section}{Список литературы}
\bibitem{Levitin} Левитин А.В. Глава 4. Метод декомпозиции: Умножение больших целых чисел и алгоритм умножения матриц Штрассена // Алгоритмы: введение в разработку и анализ. — М.: «Вильямс», 2006. — С. 189-195. 
Левитин А.В. Алгоритмы: введение в разработку и анализ.
\bibitem{Wikipedia} Wikipedia: Алгоритм Штрассена - Википедия [Электронный ресурс] // URL: \url {https://en.wikipedia.org/wiki/Strassen_algorithm} (дата обращения: 05.12.2020)
\bibitem{Algolib} Algolib. Коллекция алгоритмов [Электронный ресурс] // URL: \url {http://algolib.narod.ru/Math/Matrix.html}

\end{thebibliography}
\newpage

% Приложение
\section*{Приложение}
\addcontentsline{toc}{section}{Приложение}
В данном разделе находится листинг всего кода, написанного в рамках лабораторной работы.
\begin{lstlisting}
// strassen_alg.h

// Copyright 2020 Schekotilova Julia
#ifndef MODULES_TASK_3_SCHEKOTILOVA_JU_STRASSEN_ALG_STRASSEN_ALG_H_
#define MODULES_TASK_3_SCHEKOTILOVA_JU_STRASSEN_ALG_STRASSEN_ALG_H_
#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>
#include <vector>
#include <random>
#include <ctime>
#include <algorithm>
#include <cstdlib>

std::vector<double> createMatrix(const int n);
std::vector<double> getRandomMatrix(std::vector<double> m, int size);

const std::vector<double> simple_mult(const std::vector<double>& m1,
  const std::vector<double>& m2, int size);
const std::vector<double> addition_of2m(const std::vector<double>& matrix1,
  const std::vector<double>& matrix2, int size);
const std::vector<double> addition_of4m(const std::vector<double>& matrix1,
  const std::vector<double>& matrix2, const std::vector<double>& matrix3,
  const std::vector<double>& matrix4, int size);
const std::vector<double> subtraction_of2m(const std::vector<double>& matrix1,
  const std::vector<double>& matrix2, int size);
const std::vector<double> add_of3_sub_of4(const std::vector<double>& matrix1,
  const std::vector<double>& matrix2, const std::vector<double>& matrix3,
  const std::vector<double>& matrix4, int size);
void getFourMatrixBlocks(const std::vector<double>& A, std::vector<double>* A11,
  std::vector<double>* A12, std::vector<double>* A21, std::vector<double>* A22,
  int n_A);
const std::vector<double> getSequentialOperations(const std::vector<double>& matrix1,
  const std::vector<double>& matrix2, int size);
const std::vector<double> getParallelOperations(const std::vector<double>& matr_A,
  const std::vector<double>& matr_B, int n);

#endif  // MODULES_TASK_3_SCHEKOTILOVA_JU_STRASSEN_ALG_STRASSEN_ALG_H_
\end{lstlisting}
\begin{lstlisting}
// strassen_alg.cpp
// Copyright 2020 Schekotilova Julia
#include "../../modules/task_3/schekotilova_ju_strassen_alg/strassen_alg.h"
#include <vector>

std::vector<double> createMatrix(const int n) {
  std::vector<double> m(n * n);
  return m;
}

std::vector<double> getRandomMatrix(std::vector<double> m, int size) {
  std::mt19937 gen;
  gen.seed(static_cast<unsigned int>(time(0)));
  for (int i = 0; i < size; i++) {
    for (int j = 0; j < size; j++) {
        m[i * size + j] = gen() % 100;
    }
  }
  return m;
}

const std::vector<double> simple_mult(const std::vector<double>& m1,
  const std::vector<double>& m2, int size) {
  std::vector<double> res = createMatrix(size);
  int sum;
  for (int i = 0; i < size; i++)
    for (int j = 0; j < size; j++) {
      sum = 0;
      for (int k = 0; k < size; k++)
        sum += m1[i * size + k] * m2[k * size + j];
      res[i * size + j] = sum;
    }
  return res;
}

const std::vector<double> addition_of2m(const std::vector<double>& m1,
    const std::vector<double>& m2, int size) {
  std::vector<double> res = createMatrix(size);
  for (int i = 0; i < size; i++) {
    for (int j = 0; j < size; j++) {
        res[i * size + j] = m1[i * size + j] + m2[i * size + j];
    }
  }
  return res;
}

const std::vector<double> subtraction_of2m(const std::vector<double>& m1,
  const std::vector<double>& m2, int size) {
    std::vector<double> res = createMatrix(size);
    for (int i = 0; i < size; i++) {
      for (int j = 0; j < size; j++) {
        res[i * size + j] = m1[i * size + j] - m2[i * size + j];
      }
    }
    return res;
}

const std::vector<double> addition_of4m(const std::vector<double>& m1,
  const std::vector<double>& m2, const std::vector<double>& m3,
  const std::vector<double>& m4, int size) {
  std::vector<double> res = createMatrix(size);
  for (int i = 0; i < size; i++) {
    for (int j = 0; j < size; j++) {
      res[i * size + j] = m1[i * size + j] + m2[i * size + j] + m3[i * size + j]
          + m4[i * size + j];
      }
  }
  return res;
}


const std::vector<double> add_of3_sub_of4(const std::vector<double>& m1,
  const std::vector<double>& m2, const std::vector<double>& m3,
  const std::vector<double>& m4, int size) {
  std::vector<double> res = createMatrix(size);
  for (int i = 0; i < size; i++) {
    for (int j = 0; j < size; j++) {
      res[i * size + j] = m1[i * size + j] + m2[i * size + j] +
          m3[i * size + j] - m4[i * size + j];
    }
  }
  return res;
}

void getFourMatrixBlocks(const std::vector<double>& A, std::vector<double>* A11,
  std::vector<double>* A12, std::vector<double>* A21, std::vector<double>* A22,
    int n_A) {
  int new_sz = n_A / 2;

  (*A11).resize(new_sz * new_sz);
  (*A12).resize(new_sz * new_sz);
  (*A21).resize(new_sz * new_sz);
  (*A22).resize(new_sz * new_sz);

  for (int i = 0; i < new_sz; i++) {
    for (int j = 0; j < new_sz; j++) {
      (*A11)[i * new_sz + j] = A[i * n_A + j];
      (*A12)[i * new_sz + j] = A[i * n_A + new_sz + j];
      (*A21)[i * new_sz + j] = A[(i + new_sz) * n_A + j];
      (*A22)[i * new_sz + j] = A[(i + new_sz) * n_A + new_sz + j];
    }
  }
}

const std::vector<double> getSequentialOperations(const std::vector<double>& m1,
    const std::vector<double>& m2, int n) {
  std::vector<double> res = createMatrix(n);
  if (n <= 4) {
    res = simple_mult(m1, m2, n);
  } else {
    std::vector<double> A(4);
    std::vector<double> B(4);
    std::vector<double> C(4);
    std::vector<double> A11, A12, A21, A22, B11, B12, B21, B22;
    std::vector<double> op1, op2, op3, op4, op5, op6, op7;
    std::vector<double> C11, C12, C21, C22;
    for (int i = 0; i < n; i++)
      for (int j = 0; j < n; j++) {
        int new_idx = i * n + j, idx = 2 * i * n + j, sz = n;
        A[new_idx] = A11[idx];
        A[1*n + new_idx] = A12[idx + n];
        A[2*n + new_idx] = A21[idx + sz];
        A[3*n + new_idx] = A22[idx + sz + n];

        B[0 * n + new_idx] = B11[idx];
        B[1 * n + new_idx] = B12[idx + n];
        B[2 * n + new_idx] = B21[idx + sz];
        B[3 * n + new_idx] = B22[idx + sz + n];
      }

    std::vector<double> temp = addition_of2m(A11, A22, n);
    std::vector<double> tmp = addition_of2m(B11, B22, n);
    op1 = getSequentialOperations(temp, tmp, n);

    temp = addition_of2m(A21, A22, n);
    op2 = getSequentialOperations(temp, B11, n);

    temp = subtraction_of2m(B12, B22, n);
    op3 = getSequentialOperations(A11, temp, n);

    temp = subtraction_of2m(B21, B11, n);
    op4 = getSequentialOperations(A22, temp, n);

    temp = addition_of2m(A11, A12, n);
    op5 = getSequentialOperations(temp, B22, n);

    temp = subtraction_of2m(A21, A11, n);
    tmp = addition_of2m(B11, B12, n);
    op6 = getSequentialOperations(temp, tmp, n);

    temp = subtraction_of2m(A12, A22, n);
    tmp = addition_of2m(B21, B22, n);
    op7 = getSequentialOperations(temp, tmp, n);

    C11 = add_of3_sub_of4(op1, op4, op7, op5, n);
    C12 = addition_of2m(op3, op5, n);
    C21 = addition_of2m(op2, op4, n);
    C22 = add_of3_sub_of4(op1, op3, op6, op2, n);

    for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) {
          res[i * 2 * n + j] = C11[i * n + j];
          res[i * 2 * n + j + n] = C12[i * n + j];
           res[i * 2 * n + j + 2 * n * n] = C21[i * n + j];
           res[i * 2 * n + j + 2 * n * n + n] = C22[i * n + j];
        }
    }
  }
  return res;
}

const std::vector<double> getParallelOperations(const std::vector<double>& m1,
  const std::vector<double>& m2, int n) {
  int size, rank;
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  int sz, N;
  std::vector<double> res_m, res1_tmp, res3_tmp, res2_tmp, res4_tmp,
    res5_tmp;
  std::vector<double> A(size);
  std::vector<double> B(size);
  std::vector<double> A11, A12, A21, A22, B11, B12, B21, B22;
  MPI_Status status;
  if (n <= 64) {
    return res_m = getSequentialOperations(m1, m2, n);
  } else {
    if (rank == 0) {
      res_m = createMatrix(n);
      sz = sqrt(size);
      N = n / sz;
      std::vector<double> A11 = createMatrix(N);
      std::vector<double> A12 = createMatrix(N);
      std::vector<double> A21 = createMatrix(N);
      std::vector<double> A22 = createMatrix(N);
      std::vector<double> B11 = createMatrix(N);
      std::vector<double> B12 = createMatrix(N);
      std::vector<double> B21 = createMatrix(N);
      std::vector<double> B22 = createMatrix(N);
      getFourMatrixBlocks(A, &A11, &A12, &A21, &A22, N);
      getFourMatrixBlocks(B, &B11, &B12, &B21, &B22, N);
      MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
      for (int i = 1; i < size; i++) {
          MPI_Send(&A11[0], N * N, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
          MPI_Send(&A12[0], N * N, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
          MPI_Send(&A21[0], N * N, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
          MPI_Send(&A22[0], N * N, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
          MPI_Send(&B11[0], N * N, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
          MPI_Send(&B12[0], N * N, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
          MPI_Send(&B21[0], N * N, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
          MPI_Send(&B22[0], N * N, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
      }
    }
    if (size != 0) {
      MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
      sz = sqrt(size), N = n / sz;
      std::vector<double> A11 = createMatrix(N);
      std::vector<double> A12 = createMatrix(N);
      std::vector<double> A21 = createMatrix(N);
      std::vector<double> A22 = createMatrix(N);
      std::vector<double> B11 = createMatrix(N);
      std::vector<double> B12 = createMatrix(N);
      std::vector<double> B21 = createMatrix(N);
      std::vector<double> B22 = createMatrix(N);
      for (int i = 0; i < sz; i++) {
        MPI_Recv(&A11[0], N * N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);
        MPI_Recv(&A12[0], N * N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);
        MPI_Recv(&A21[0], N * N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);
        MPI_Recv(&A22[0], N * N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);
        MPI_Recv(&B11[0], N * N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);
        MPI_Recv(&B12[0], N * N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);
        MPI_Recv(&B21[0], N * N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);
        MPI_Recv(&B22[0], N * N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status);
      }
    }
    res2_tmp = getSequentialOperations(A11, B11, N);
    res3_tmp = getSequentialOperations(A12, B12, N);
    res4_tmp = getSequentialOperations(A21, B21, N);
    res5_tmp = getSequentialOperations(A22, B22, N);

    if (size == 4)
      res1_tmp = addition_of2m(res2_tmp, res3_tmp, N);
    if (size == 16)
      res1_tmp = addition_of4m(res2_tmp, res3_tmp, res4_tmp, res5_tmp, N);

    if (rank != 0) {
      MPI_Send(&res1_tmp, N * N, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD);
    }
    if (rank == 0) {
      int coeff = sqrt(size);
      for (int i = 0; i < N; i++)
        for (int j = 0; j < N; j++)
          res_m[coeff * i * N + j] = res1_tmp[i * N + j];
      for (int k = 1; k < size; k++) {
        MPI_Recv(&res1_tmp, N * N, MPI_DOUBLE, k, 0, MPI_COMM_WORLD, &status);
        for (int i = 0; i < N; i++)
          for (int j = 0; j < N; j++)
            res_m[(k / coeff) * N * n + (k % coeff) * N + coeff * i * N + j]
            = res1_tmp[i * N + j];
      }
      return res_m;
    }
  }
  return res_m;
}
\end{lstlisting}
\begin{lstlisting}
// main.cpp
// Copyright 2020 Schekotilova Julia
#include <gtest-mpi-listener.hpp>
#include <gtest/gtest.h>
#include <vector>
#include "./strassen_alg.h"

TEST(TEST_STRASSEN_ALG, Test_addition_of_2_matrix) {
  double eps = 0.001;
  int n = 2;
  int rank;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  std::vector<double> A = { 1.1, 2.2, 3.3, 4.4};
  std::vector<double> B = { -1.1, -2.2, -3.3, -4.4};
  std::vector<double> C;
  std::vector<double> res = { 0, 0, 0, 0 };
  if (rank == 0) {
    ASSERT_NO_THROW(C = addition_of2m(A, B, n));
    for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) {
        EXPECT_NEAR(C[i * n + j], res[i * n + j], eps);
      }
    }
  }
}

TEST(TEST_STRASSEN_ALG, Test_subtraction_of_2_matrix) {
  int rank;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  int n = 4;
  std::vector<double> A = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
      16 };
  std::vector<double> B = { 2, 34, 65, 6, 75, 8, 26, 7, 4, 12, 27, 22, 20, 1,
      23, 48 };
  std::vector<double> C = subtraction_of2m(B, A, n);
  std::vector<double> res = { 1, 32, 62, 2, 70, 2, 19, -1, -5, 2, 16, 10, 7,
      -13, 8, 32};
  if (rank == 0) {
    ASSERT_NO_THROW(C = subtraction_of2m(B, A, n););
    for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) {
        EXPECT_NEAR(C[j + i * n], res[j + i * n], 1e-5);
      }
    }
  }
}

TEST(TEST_STRASSEN_ALG, Test_simple_multiplication) {
    int size;
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    if (size < 2) {
        int n = 4;
        std::vector<double> A = createMatrix(n);
        std::vector<double> B = createMatrix(n);
        std::vector<double> C = createMatrix(n);
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                A[i * n + j] = i + 1;
                B[i * n + j] = i + 1;
                C[i * n + j] = 10 * (i + 1);
            }
        }
        std::vector<double> simple = simple_mult(A, B, n);
        for (int k = 0; k < n; k++)
            for (int l = 0; l < n; l++)
                ASSERT_TRUE(C[k * n + l] == simple[k * n + l]);
    }
}

TEST(TEST_STRASSEN_ALG, Test_sequential_operations) {
  int size;
  MPI_Comm_size(MPI_COMM_WORLD, &size);
    int n = 4;
    std::vector<double> A = createMatrix(n);
    std::vector<double> B = createMatrix(n);
    getRandomMatrix(A, n);
    getRandomMatrix(B, n);
    std::vector<double> simple = simple_mult(A, B, n);
    std::vector<double> strassen = getSequentialOperations(A, B, n);
    for (int k = 0; k < n; k++)
      for (int l = 0; l < n; l++)
        ASSERT_TRUE(strassen[k * n + l] == simple[k * n + l]);
}

TEST(TEST_STRASSEN_ALG, Test_parallel_sequential_time) {
  int rank, size;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  if (rank == 0) {
    int n = 4;
    std::vector<double> A = createMatrix(n);
    std::vector<double> B = createMatrix(n);
    for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) {
        A[i * n + j] = i*15035195.2846+ 1;
        B[i * n + j] = i*1005002 + 1;
      }
    }
    double timeSeque = MPI_Wtime();
    std::vector<double> seq = getSequentialOperations(A, B, n);
    double timeS = MPI_Wtime();
    double timeParal = MPI_Wtime();
    std::vector<double> parallel = getParallelOperations(A, B, n);
    double timeP = MPI_Wtime();
    for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) {
          ASSERT_TRUE(parallel[i * n + j] == seq[i * n + j]);
      }
    }
    printf("The parallel   time: %f seconds\n", timeP-timeParal);
    printf("The sequential time: %f seconds\n", timeS - timeSeque);
  }
}

TEST(TEST_STRASSEN_ALG, Test_parallel_operations) {
  int rank, size;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  if (rank == 0) {
    int n = 4;
    std::vector<double> A = createMatrix(n);
    std::vector<double> B = createMatrix(n);
    for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) {
        A[i * n + j] = i * 15035195.2846 + 1;
        B[i * n + j] = i * 1005002 + 1;
      }
    }
    std::vector<double> simple = simple_mult(A, B, n);
    double timeParal = MPI_Wtime();
    std::vector<double> parallel = getParallelOperations(A, B, n);
    double timeP = MPI_Wtime();
    for (int i = 0; i < n; i++)
      for (int j = 0; j < n; j++)
        ASSERT_TRUE(parallel[i * n + j] == simple[i * n + j]);
    printf("The parallel   time: %f seconds\n", timeP - timeParal);
  }
}

int main(int argc, char** argv) {
  ::testing::InitGoogleTest(&argc, argv);
  MPI_Init(&argc, &argv);

  ::testing::AddGlobalTestEnvironment(new GTestMPIListener::MPIEnvironment);
  ::testing::TestEventListeners& listeners =
    ::testing::UnitTest::GetInstance()->listeners();

  listeners.Release(listeners.default_result_printer());
  listeners.Release(listeners.default_xml_generator());

  listeners.Append(new GTestMPIListener::MPIMinimalistPrinter);
  return RUN_ALL_TESTS();
}
\end{lstlisting}

\end{document}